{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing\n",
    "import numpy as np # working with arrays\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "from termcolor import colored as cl # text customization\n",
    "import itertools # advanced tools\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # data normalization\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision tree algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN algorithm\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression algorithm\n",
    "from sklearn.svm import SVC # SVM algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm\n",
    "from xgboost import XGBClassifier # XGBoost algorithm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix # evaluation metric\n",
    "from sklearn.metrics import accuracy_score # evaluation metric\n",
    "from sklearn.metrics import f1_score # evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\User\\Desktop\\creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "amount = df['Amount'].values\n",
    "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n",
      "(275663, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.9991583957281328\n",
      "F1 score of the Decision Tree model is 0.7521367521367521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68770,    18],\n",
       "       [   40,    88]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "tree_yhat = DT.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)))\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat)))\n",
    "confusion_matrix(y_test, tree_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is 0.999288989494457\n",
      "F1 score of the Decision Tree model is 0.7896995708154506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68775,    13],\n",
       "       [   36,    92]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth = 8, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "tree_yhat = DT.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)))\n",
    "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat)))\n",
    "confusion_matrix(y_test, tree_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.9994486040977422\n",
      "F1 score of the K-Nearest Neighbors model is 0.831858407079646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68784,     4],\n",
       "       [   34,    94]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-Nearest Neighbors\n",
    "\n",
    "n = 3\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
    "confusion_matrix(y_test, knn_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.9993325207498984\n",
      "F1 score of the K-Nearest Neighbors model is 0.8034188034188035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68776,    12],\n",
       "       [   34,    94]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-Nearest Neighbors\n",
    "\n",
    "n = 5\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
    "confusion_matrix(y_test, knn_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is 0.999288989494457\n",
      "F1 score of the K-Nearest Neighbors model is 0.7949790794979079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68772,    16],\n",
       "       [   33,    95]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-Nearest Neighbors\n",
    "\n",
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_yhat)))\n",
    "confusion_matrix(y_test, knn_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is 0.9989552498694062\n",
      "F1 score of the Logistic Regression model is 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68772,    16],\n",
       "       [   56,    72]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)))\n",
    "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)))\n",
    "confusion_matrix(y_test, lr_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Support Vector Machines model is 0.999318010331418\n",
      "F1 score of the Support Vector Machines model is 0.7813953488372093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68785,     3],\n",
       "       [   44,    84]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Machines\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_yhat)))\n",
    "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_yhat)))\n",
    "confusion_matrix(y_test, svm_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is 0.9991583957281328\n",
      "F1 score of the Random Forest model is 0.7314814814814815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68779,     9],\n",
       "       [   49,    79]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_yhat)))\n",
    "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_yhat)))\n",
    "confusion_matrix(y_test, rf_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBoost model is 0.999506645771664\n",
      "F1 score of the XGBoost model is 0.8495575221238937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68786,     2],\n",
       "       [   32,    96]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)))\n",
    "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)))\n",
    "confusion_matrix(y_test, xgb_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                600       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                504       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                500       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                504       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,133\n",
      "Trainable params: 2,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential([\n",
    "    Dense(units=20, input_dim = X_train.shape[1], activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=20,activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6892/6892 [==============================] - 15s 2ms/step - loss: 0.0100 - accuracy: 0.9987\n",
      "Epoch 2/5\n",
      "6892/6892 [==============================] - 13s 2ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "6892/6892 [==============================] - 14s 2ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "6892/6892 [==============================] - 14s 2ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "6892/6892 [==============================] - 13s 2ms/step - loss: 0.0029 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d3162bd3d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=30, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154/2154 [==============================] - 3s 1ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Test Accuracy: 99.92%\n",
      "Test Loss: 0.00409175269305706\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: {:.2f}%\\nTest Loss: {}'.format(score[1]*100,score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154/2154 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "y_pred = model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(cm, annot=True, fmt='.0f', cmap='cividis_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10)                300       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 27)                567       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                840       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,958\n",
      "Trainable params: 1,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ = Sequential([\n",
    "    Dense(units=10, input_dim = X_train.shape[1], activation='relu'),\n",
    "    Dense(units=20,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=27,activation='relu'),\n",
    "    Dense(units=30,activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6892/6892 [==============================] - 12s 2ms/step - loss: 0.0112 - accuracy: 0.9986\n",
      "Epoch 2/5\n",
      "6892/6892 [==============================] - 13s 2ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "6892/6892 [==============================] - 13s 2ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "6892/6892 [==============================] - 14s 2ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "6892/6892 [==============================] - 12s 2ms/step - loss: 0.0032 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d3194c2940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_.fit(X_train, y_train, batch_size=30, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154/2154 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Test Accuracy: 99.92%\n",
      "Test Loss: 0.004038030747324228\n"
     ]
    }
   ],
   "source": [
    "score = model_.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: {:.2f}%\\nTest Loss: {}'.format(score[1]*100,score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154/2154 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model_.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(cm, annot=True, fmt='.0f', cmap='cividis_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
